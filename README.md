# AI Log Explainer ğŸ› ï¸

A minimalist CLI tool that turns raw JSONâ€‘formatted service logs into short, humanâ€‘friendly explanations using the OpenAI Chatâ€¯Completions API.

## QuickÂ start

```bash
# 1.  Clone or download the zip, then:
cd ai_log_explainer
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 2.  Make your OpenAI key available
export OPENAI_API_KEY="skâ€‘..."

# 3.  Pipe logs or pass a file
cat sample_logs.jsonl | python main.py
#  â€“Â orÂ â€“
python main.py --logfile sample_logs.jsonl --model gpt-4o-mini --lines 150
```

## What it does
1. Reads newlineâ€‘delimited JSON log entries (from a file or **stdin**).
2. Keeps the last *N* lines (defaultÂ =Â 120) to stay within token limits.
3. Sends them to the Chatâ€¯Completions endpoint with a purposeâ€‘built
   SRE prompt.
4. Prints the resulting oneâ€‘ or twoâ€‘sentence rootâ€‘cause analysis /
   recommendation.

## Configuration

* `OPENAI_API_KEY`Â â€” must be set as envâ€‘var **or** put in `config.toml`
  (see `config.example.toml`).
* `--model`Â Â Â Â Â Â â€” any ChatÂ model your key can access (`gpt-4o`, `gpt-4o-mini`, etc).
* `--lines`Â Â Â Â Â Â â€” how many recent log entries to include (default 120).

## Files

```
ai_log_explainer/
â”œâ”€â”€ main.py               # CLI entryâ€‘point
â”œâ”€â”€ requirements.txt      # pip deps
â”œâ”€â”€ config.example.toml   # optional key storage
â”œâ”€â”€ sample_logs.jsonl     # toy data for a dryâ€‘run
â””â”€â”€ README.md             # this doc
```

## Cost âš ï¸
Each run consumes OpenAI tokens for both prompt (your logs) and
completion. When calling large models with many log lines the cost
can add up quickly.

---
MITâ€‘licensed â€” happy debugging!
